Outliers are unreasonable values, with normal outlier detection the entire dataset is deleted, showing data has strange distribution but is valid and should not be deleted 

Was originally using accuracy as metric, changed to cross validation and F1 score for a more telling evaluation


decreased amount of K and estimators tested to 1 - 30 (included)

removed 'sigmoid' and 'precomputed' kernel mode from SVM due to poor performance


Tried to test LinearSVC specifically after seeing 'linearÃ¬ kernel was performing well (speed and accuracy wise)


Chose to test clustering algorithms due to the distribution of data. Will test K-means and GMM (Gaussian Mixture Model)

Check for overfitting or underfitting!

Am i working on test data and not on validation data? Specify it in the report if i split test into test and validation!


GMM is good to detect outliers, if a point has a very low percentage to belong to any cluster it means it is an outlier.


analisi con PCA per vedeere i componenti quanta variance aggiungono, poi valuto clustering su raw data e su PCA data.
Prendere feature poco leggibili e fare quello con pCA e poi con altri dati categorici


Drop redshift because its too good of a feature to classify and makes the models job too easy
due to this i have to do some feature engineering to go about correlated features but still keep crucial color information for my model's evaluation
-> Created synthetic featues to describe colors without the need to keep u g z 

Compared training with
    1. redshift + no synthetic features
    2. no redshift + synthetic features
and performance is better in case 2

Clustering is not influenced by the difference in case 1 or 2 since PCA selects the same features as best in either case